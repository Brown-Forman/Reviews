---
title: "Tripadvisor"
author: "Thi Allgood"
date: "3/23/2020"
output: html_document
---

```{r}
library(rvest)
library(tidyverse)
library(lubridate)
library(ggplot2)
library(tm)
library(scales)
library(topicmodels)
library(rvest)
library(purrr)
library(rvest)
library(stringr)
library(rvest)

library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
```

```{r}
# function to separate content of reviews and response from owner
func_body <- function(body,responded.yn){
  response = rep(NA,10)
  content = rep(NA,10)
  n = length(responded.yn)
  i = 1
  a = 1
  while (a < n){
    if (responded.yn[a] == FALSE & responded.yn[a+1] == TRUE){
      content[i] = body[a]
      response[i] = body[a+1]
      i = i + 1
      a = a + 2
    } else {
      content[i] = body[a]
      response[i] = NA
      i = i + 1
      a = a + 1
    }
  }
  if (responded.yn[n] == FALSE){
    content[10] = body[n]
    response[10] = NA
  }
  df = data.frame(content,response) %>%
    mutate(content = as.character(content),
           response = as.character(response))
  return(df)
}

# function to get csv reivews from Tripdvisor
tripadvisor <- function(url){
  # get the name of the restaurant
  reviews <- read_html(url)
  split_url <- str_split(url,'Reviews')
  name <- split_url[[1]][2]
  name <- str_split(name, ".html")
  name <- name[[1]][1]
  
  # find the the lnumber of the last page listed in the bottom of the main page
  npages <- reviews %>% 
          html_nodes(" .pageNum ") %>% 
          html_attr(name="data-page-number") %>%
          as.numeric() %>%
          max()
    
  # Get headline of reviews
  headline <- reviews %>%
    html_nodes("span.noQuotes") %>%
    html_text()
  
  #get body of reviews, this include customer reviews and response from owner
  body <- reviews %>%
    html_nodes("p.partial_entry") %>%
    html_text()
  
  # get a yes/no vector to see if an element in the body is a response (Yes), otherwise No
  responded.yn <- reviews %>%
      html_nodes("div.mgrRspnInline") %>%
      html_text()
  responded.yn <-strsplit(responded.yn,'Responded ')
  responded.yn <- sapply(responded.yn,function(x) x[2])
  # tripadvisor was founded in 2000 so this shoud captured all the reviews '20..'
  responded.yn <- str_replace_all(responded.yn,'20..','qwertyuiop') 
  responded.yn <- str_split(responded.yn,'qwertyuiop')
  responded.yn <- sapply(responded.yn,function(x) x[2])
  responded.yn <- body %in% responded.yn
  
  # get a dataframe of 2 columns: reviews and response, if owner did not response: NA
  df <- func_body(body,responded.yn)
  response <- df$response
  content <- df$content
  
  # get stars that customer give in the review
  star <- reviews %>%
    html_nodes("span.ui_bubble_rating") %>%
    html_attr("alt") 
  star <- star[!is.na(star)]
  star <- star[3:length(star)]
  star <- strsplit(star, " ")
  star <- as.numeric(lapply(star, `[[`, 1))
  
  # count total headlines/reviews total
  l_headline = length(headline)
  length_df1 = data.frame(l_headline)
  
  # iterate to the next page until all reviews are captured
  n = 10
  for (o in 1:(npages-1)){
    n.character = as.character(n)
    url.temp1 <- paste0(split_url[[1]][1],"Reviews")
    url.temp2 <- split_url[[1]][2]
    url.temp = paste0(url.temp1,
                 '-or',n.character,url.temp2)
    reviews.temp = read_html(url.temp)
    
    headline.temp = reviews.temp %>%
      html_nodes("span.noQuotes") %>%
      html_text()
    headline = append(headline,headline.temp)
    
    # body including reviews and response from owner, need to look at responded.yn.temp to distinguish between review and response
    body.temp <- reviews.temp %>%
    html_nodes(".entry .partial_entry") %>%
    html_text()
    
    # Owner responded yes or no
    responded.yn.temp <- reviews.temp %>%
      html_nodes("div.mgrRspnInline") %>%
      html_text()
    responded.yn.temp <- strsplit(responded.yn.temp,"Responded ")
    responded.yn.temp <- sapply(responded.yn.temp,function(x) x[2])
    responded.yn.temp <- str_replace_all(responded.yn.temp,', 20..',"qwertyuiop")
    responded.yn.temp <- strsplit(responded.yn.temp,'qwertyuiop')
    responded.yn.temp <- sapply(responded.yn.temp,function(x) x[2])
    responded.yn.temp <- body.temp %in% responded.yn.temp 
    
    df.temp <- func_body(body.temp,responded.yn.temp)
   
    content.temp = df.temp$content
    content = append(content,content.temp)
    
    response.temp = df.temp$response
    response = append(response,response.temp)
    
    star.temp <- reviews.temp %>%
      html_nodes("span.ui_bubble_rating") %>%
      html_attr("alt") 
    star.temp <- star.temp[!is.na(star.temp)]
    star.temp <- star.temp[3:length(star.temp)]
    star.temp <- strsplit(star.temp, " ")
    star.temp <- as.numeric(lapply(star.temp, `[[`, 1))
    star <- append(star,star.temp)
    n = n + 10
    print(paste(o,'/',(npages-1)))
  }
  
  #return a dataframe of reviews
  content = content[!is.na(content)]
  total_reviews = length(headline)
  response = response[1:total_reviews]
  star = star[1:total_reviews]
  df = data.frame(headline,content,response,star)
  write_csv(df,paste0(name,'.csv'))
}


```

```{r}
url <- "https://www.tripadvisor.com/Restaurant_Review-g39604-d1121798-Reviews-The_Cafe-Louisville_Kentucky.html#REVIEWS"
df <- tripadvisor(url)
```


```{r}
# Function to get word cloud
cloud <- function(string_content,filter_words){
  docs0 <- Corpus(VectorSource(string_content))
  inspect(docs0)
  toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
  
  docs <- tm_map(docs0, toSpace, "/")
  docs <- tm_map(docs, toSpace, "@")
  docs <- tm_map(docs, toSpace, "\\|")
  
  # Convert the text to lower case
  docs <- tm_map(docs, content_transformer(tolower))
  # Remove numbers
  docs <- tm_map(docs, removeNumbers)
  # Remove english common stopwords
  docs <- tm_map(docs, removeWords, stopwords("english"))
  # Remove your own stop word
  # specify your stopwords as a character vector
  docs <- tm_map(docs, removeWords, filter_words) 
  # Remove punctuations
  docs <- tm_map(docs, removePunctuation)
  # Eliminate extra white spaces
  docs <- tm_map(docs, stripWhitespace)
  # Text stemming
  # docs <- tm_map(docs, stemDocument)
  
  dtm <- TermDocumentMatrix(docs)
  m <- as.matrix(dtm)
  v <- sort(rowSums(m),decreasing=TRUE)
  d <- data.frame(word = names(v),freq=v)
  head(d, 10)
  
  set.seed(1234)
  wordcloud(words = d$word, freq = d$freq, min.freq = 1,
            max.words=200, random.order=FALSE, rot.per=0.35, 
            colors=brewer.pal(8, "Dark2"))
}
```

```{r}
string_content <- paste(df$content,collapse = " ")
filter_words <- c("the","and")
cloud(string_content,filter_words)
# bourbon
bourbon <- df$content[grepl("bourbon", df$content)]
filter_words <- c("the","and","bourbon")
cloud(bourbon,filter_words)
```


iterate throug all restaurants in New York
```{r}
options(timeout= 4000000)
a = 1
# Because of sponsored restaurants, total list of restaurant is ether 36 or 37, refresh pages until we get a list of 37 restaurant.
while (a != 37){
  city_url <- "https://www.tripadvisor.com/Restaurants-g60763-New_York_City_New_York.html" 
  city <- read_html(city_url)

  link <- city %>%
    html_nodes("a._15_ydu6b") %>%
    html_attr("href")
  a = length(link)
}
sponsored <- c(1,7,13,19,25,31,37)
not.sponsored <- c(1:37)
not.sponsored <- not.sponsored[which(!not.sponsored %in% sponsored)]

link <- link[not.sponsored]

names <- link %>%
  strsplit("-")
names <- sapply(names,function(x) x[5])


about.restaurant <- city %>%
  html_nodes("span._1p0FLy4t") %>%
  html_text()

#  cant get reviews to align
# reivews <- city %>%
#   html_nodes("span.w726Ki5B") %>%
#   html_text() 

price.range <- about.restaurant[str_detect(about.restaurant,"\\$")]
price.range <- price.range[not.sponsored]

price.range <- price.range %>%
 str_replace("\\$\\$\\$\\$","high") %>%
 str_replace("\\$\\$ - \\$\\$\\$","medium") %>%
 str_replace("\\$","low")

pages <- city %>%
  html_nodes("a.pageNum.taLnk") %>%
  html_attr("data-page-number") %>%
  as.numeric() %>%
  max()
city.temp <- city
for(i in 1:(pages-1)){
  a = 1
  while (a != 37){
    next_URL <- city.temp %>%
        html_nodes(".nav.next") %>%
        html_attr("href")
    next_URL <- paste0("https://www.tripadvisor.com", next_URL)
  
    city.temp <- read_html(next_URL)
  
    link.temp <- city.temp %>%
      html_nodes("a._15_ydu6b") %>%
      html_attr("href")
    
    a = length(link.temp)
}
 
  link.temp <- link.temp[not.sponsored]
  
  link <- append(link,link.temp)
  
  names.temp <- link.temp %>%
    strsplit("-")
  names.temp <- sapply(names.temp,function(x) x[5])
  names <- append(names,names.temp)
  
  about.restaurant.temp <- city.temp %>%
    html_nodes("span._1p0FLy4t") %>%
    html_text()
  
  #reviews.temp <- about.restaurant.temp[str_detect(about.restaurant.temp,"reviews")]
  price.range.temp <- about.restaurant.temp[str_detect(about.restaurant.temp,"\\$")]
  price.range.temp <- price.range.temp[not.sponsored]

  price.range.temp <- price.range.temp %>%
    str_replace("\\$\\$\\$\\$","high") %>%
    str_replace("\\$\\$ - \\$\\$\\$","medium") %>%
    str_replace("\\$","low")

  price.range <- append(price.range,price.range.temp)
  
  #print(paste(i,pages-1))
  print(paste("link",length(link)))
  print(paste("names",length(names)))
  print(paste("price range", length(price.range)))
}

restaurants <- data.frame(names,link,price.range)

```



